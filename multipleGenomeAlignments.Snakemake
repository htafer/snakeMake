# =====================================
# multipleGenomeAlignments.Snakemake
# =====================================
#
# Purpose:
#   This Snakemake workflow performs whole-genome alignments between multiple
#   species using a combination of tools from the UCSC Genome Browser toolkit.
#   It includes steps for repeat masking, pairwise alignment, chaining,
#   netting, and multiple alignment construction.
#
# Workflow Steps:
#   1. Repeat masking using RepeatMasker
#   2. Splitting genomes into chromosomes
#   3. Pairwise alignments using LASTZ
#   4. Converting alignments to PSL format
#   5. Chaining alignments
#   6. Creating alignment nets
#   7. Converting to MAF format
#   8. Multiple alignment using ROAST
#
# Input Requirements:
#   - Reference genome FASTA file (specified by REFGENOME)
#   - Query genome FASTA files (specified in IDS)
#   - Tree file in Newick format (specified by TREE)
#   - Working directory path (WORKDIR)
#   - Computation directory path (COMPUTEDIR)
#
# Output Files:
#   - Masked genome files (*.masked)
#   - Pairwise alignments (*.lastz)
#   - Chain files (*.chain)
#   - Net files (*.net)
#   - MAF files (*.maf)
#   - Final multiple alignment (roaster.maf)
#
# Dependencies:
#   - RepeatMasker
#   - LASTZ
#   - Kent tools (axtChain, chainNet, etc.)
#   - GNU Parallel
#   - ROAST
#
# Usage:
#   snakemake -s multipleGenomeAlignments.Snakemake --cores [N]
#
# Author: htafer
# Last Updated: 2025-07-28
#
# =====================================
#   - Alignment files (MAF, GFF)
#   - Summary statistics
#
# Usage:
#   snakemake -d $(pwd) -s $(pwd)/multipleGenomeAlignments.Snakemake --stats snakemake.stats -j 100 --cluster 'qsub {params.cluster}'
#
# ===============================
#look at https://www.mail-archive.com/bioinfo-general-nci@list.nih.gov/msg00018.html
#Check parallell environment on cluster.

REFGENOME="exoDer"
REFGENOMENAME=REFGENOME+".ref"
WORKDIR="/home/lv70539/htafer/testAlignment"
COMPUTEDIR="/scratch"
FILES=WORKDIR+"/{id}.fna"
IDS,=glob_wildcards(FILES)
print("%s",IDS)


TREE="((((exoDer claImm) (fonPed)) (horWer)) (canAlb))"

#Which rules are run locally
localrules: all,splitFile,splitFileREF,genomeSize,genomeSizeREF,clean,runRNAcode, runRNAzRandom, runRNAz,RNAzShuffle,splitAlignmentsRandom, splitAlignments

rule all:
     input: expand(REFGENOME+".{type}",type=("RNAz", "RNAzShuffle","RNAcode"))

#RNAz RNAcode

rule runRNAcode:
     input: REFGENOME+".alidir"
     output: rnacode=REFGENOME+".RNAcode",gff=REFGENOME+".RNAcode.gtf"
     params: cluster="-cwd -V"
     shell:"""
     mkdir -p {output.rnacode}
     cd {WORKDIR}/{input}
     parallel -j 32 'echo "cat {{}} | parallel -kN1 --recstart \\\"a score\\\" --pipe RNAcode  --gtf -b -r -s --cutoff 0.01 > {WORKDIR}/{output.rnacode}/rnaCode.{{}}" | qsub -V -cwd -sync y' ::: xx*
     cd {WORKDIR}/{output.rnacode}
     cat rnaCode.xx* | grep -v "sites" | sort -k 1,1 -k 4,4g -k 5,5g | sed -r 's/\|/\t/' | cut -f 1-5,7- > /dev/shm/temp &&  bedtools merge -i /dev/shm/temp -s -scores min  | perl -lane 'BEGIN{$count=0} print "$F[0]\tRNAcode\tRNAcode\t$F[1]\t$F[2]\t$F[3]\t$F[4]\t.\tgene_id \"RNAcode".$count."; transcript_id \"transcript RNAcode".$count.";";$count++;' > {WORKDIR}/{output.gff}
     """

rule runRNAzRandom:
     input: REFGENOME+".alidirRand"
     output: rnaz=REFGENOME+".RNAzShuffle", gff=REFGENOME+".RNAzShuffle.gff"
     params: cluster="-cwd -V"
     shell:"""
     mkdir -p {output.rnaz}
     cd {WORKDIR}/{input}
     parallel -j 32 'echo "cat {{}} | parallel -kN1 --recstart \\\"a score\\\" --pipe RNAz --both-strands --no-shuffle --cutoff=0.5 > {WORKDIR}/{output.rnaz}/rnaz.{{}}" | qsub -V -cwd -sync y' ::: xx*
     cd {WORKDIR}/{output.rnaz}
     cat rnaz.* | rnazCluster.pl | rnazIndex.pl --gff > {WORKDIR}/{output.gff}
     """


rule runRNAz:
     input: REFGENOME+".alidir"
     output: rnaz=REFGENOME+".RNAz", gff=REFGENOME+".RNAz.gff"
     params: cluster="-cwd -V"
     shell:"""
     mkdir -p {output.rnaz}
     cd {WORKDIR}/{input}
     parallel -j 32 'echo "cat {{}} | parallel -kN1 --recstart \\\"a score\\\" --pipe RNAz --both-strands --no-shuffle --cutoff=0.5 > {WORKDIR}/{output.rnaz}/rnaz.{{}}" | qsub -V -cwd -sync y' ::: xx*
     cd {WORKDIR}/{output.rnaz}
     cat rnaz.* | rnazCluster.pl | rnazIndex.pl --gff > {WORKDIR}/{output.gff}
     """


rule splitAlignments:
     input: "roaster.maf"
     output: dir=REFGENOME+".alidir"
     params: cluster="-cwd -V"
     shell:"""
     mkdir -p {WORKDIR}/{output.dir}
     cat {WORKDIR}/{input} | rnazWindow.pl --window=120 --slide=40 | parallel -kN200 --recstart 'a score' --pipe echo JOB\; cat \;echo -n ''\;  > {WORKDIR}/{output.dir}/windows16.maf
     cd {WORKDIR}/{output.dir}
     cat windows16.maf | csplit - /JOB/+1 {{*}}
     """

rule splitAlignmentsRandom:
     input: "roaster.maf"
     output: dir=REFGENOME+".alidirRand"
     params: cluster="-cwd -V"
     shell:"""
     mkdir -p {WORKDIR}/{output.dir}
     cat {WORKDIR}/{input} | rnazRandomizeAln.pl | rnazWindow.pl --window=120 --slide=40 | parallel -kN200 --recstart 'a score' --pipe echo JOB\; cat \;echo -n ''\;  > {WORKDIR}/{output.dir}/windows16.maf
     cd {WORKDIR}/{output.dir}
     cat windows16.maf | csplit - /JOB/+1 {{*}}
     """


## Multiple Alignment Rules ##
# Rule: roasting
# Purpose: Combines multiple pair-wise alignments into a multiple alignment using ROAST
# Input: Individual MAF files from pairwise alignments
# Output: A single MAF file containing the multiple alignment
rule roasting:
    input: 
        mafs = expand(REFGENOME+".{id}.sing.maf", id=IDS)
    output: 
        maf = "roaster.maf"
    params: 
        cluster="-cwd -V"
    log:
        "logs/roasting/roast.log"
    shell:"""
        (roast T={COMPUTEDIR}/ E={REFGENOME} \"{TREE}\" {input.mafs} {COMPUTEDIR}/{output.maf} && \
        mv {COMPUTEDIR}/{output.maf} {WORKDIR}/{output.maf}) 2> {log}
        """


# Rule: netMaf
# Purpose: Converts network and chain files to MAF format through AXT intermediate
# Input: Network, chain, and genome files
# Output: MAF format alignment file
rule netMaf:
    input:
        net = "{id}.fna.split.net",
        chain = "{id}.fna.split.preChain",
        split = "{id}.fna.split",
        sizes = "{id}.fna.sizes",
        ref = REFGENOME+".ref"
    output:
        maf = "{REFGENOME}.{id}.sing.maf"
    params:
        cluster="-cwd -V"
    log:
        "logs/netmaf/{id}.log"
    shell: """
        (netToAxt {input.net} {input.chain} {input.ref}.split/ {input.split}/ stdout | \
        axtSort stdin stdout | \
        axtToMaf stdin {input.ref}.sizes {input.sizes} {COMPUTEDIR}/{output.maf} \
            -tPrefix={input.ref}. \
            -qPrefix=`echo {input.sizes} | sed -r 's/.fna.+/./'` && \
        mv {COMPUTEDIR}/{output.maf} {WORKDIR}/{output.maf}) 2> {log}
        """

# Rule: chainNet
# Purpose: Creates alignment nets from chains, filtering for synteny
# Input: Pre-chain file and genome sizes
# Output: Network format alignment file
rule chainNet:
    input:
        prechain = "{id}.fna.split.preChain",
        query_sizes = "{id}.fna.sizes",
        target_sizes = REFGENOME+".ref.sizes"
    output:
        net = "{id}.fna.split.net"
    params:
        cluster="-cwd -V",
        min_space = 1  # Minimum space between alignment blocks
    log:
        "logs/chainnet/{id}.log"
    shell:"""
        (chainNet {WORKDIR}/{input.prechain} \
            -minSpace={params.min_space} \
            {WORKDIR}/{input.target_sizes} \
            {WORKDIR}/{input.query_sizes} \
            stdout /dev/null | \
        netSyntenic stdin {COMPUTEDIR}/{output.net} && \
        mv {COMPUTEDIR}/{output.net} {WORKDIR}/{output.net}) 2> {log}
        """

## Chaining Rules ##
# Rule: allChain
# Purpose: Merges and sorts alignment chains, then prepares them for netting
# Input: AXT format alignments and genome sizes
# Output: Sorted chain file and preprocessed chain file for netting
rule allChain:
    input:
        axt = "{id}.fna.split.axt",
        query_sizes = "{id}.fna.sizes",
        target_sizes = REFGENOME+".ref.sizes"
    output:
        chain = "{id}.fna.split.chain",
        prechain = "{id}.fna.split.preChain"
    params:
        cluster="-cwd -V"
    log:
        "logs/allchain/{id}.log"
    shell:"""
        (chainMergeSort {WORKDIR}/{input.axt}/* > {COMPUTEDIR}/{output.chain} && \
        chainPreNet {COMPUTEDIR}/{output.chain} \
            {WORKDIR}/{input.target_sizes} \
            {WORKDIR}/{input.query_sizes} \
            {COMPUTEDIR}/{output.prechain} && \
        mv {COMPUTEDIR}/{output.chain} {WORKDIR}/{output.chain} && \
        mv {COMPUTEDIR}/{output.prechain} {WORKDIR}/{output.prechain}) 2> {log}
        """

# Rule: axtChain
# Purpose: Creates alignment chains from PSL files using parallel processing
# Input: PSL alignments and split genome files
# Output: Directory of AXT format alignment chains
rule axtChain:
    input:
        psl = "{id}.fna.split.psl",
        target_split = REFGENOME+".ref.split",
        query_split = "{id}.fna.split"
    output:
        axt = directory("{id}.fna.split.axt")
    params:
        cluster="-cwd -V",
        threads = 16,
        gap_model = "loose"  # Gap scoring model for alignment chains
    log:
        "logs/axtchain/{id}.log"
    shell:"""
        (prefix=`date --rfc-3339=ns | md5sum | head -c 16` && \
        mkdir -p {COMPUTEDIR}/${{prefix}} && \
        parallel -j {params.threads} \
            --tmpdir {COMPUTEDIR}/${{prefix}} \
            --files \
            axtChain {{}} \
            {WORKDIR}/{input.target_split} \
            {WORKDIR}/{input.query_split} \
            stdout \
            -linearGap={params.gap_model} \
            -psl \
            ::: {WORKDIR}/{input.psl}/* && \
        mv {COMPUTEDIR}/${{prefix}} {WORKDIR}/{output.axt}) 2> {log}
        """
## Alignment Format Conversion Rules ##
# Rule: lavtopsl
# Purpose: Converts LASTZ LAV output to PSL format using parallel processing
# Input: Directory of LAV files from LASTZ
# Output: Directory of PSL format alignments
rule lavtopsl:
    input:
        lav = "{id}.fna.split.lastz"
    output:
        psl = directory("{id}.fna.split.psl")
    params:
        cluster="-cwd -V",
        threads = 16
    log:
        "logs/lavtopsl/{id}.log"
    shell: """
        (prefix=`date --rfc-3339=ns | md5sum | head -c 16` && \
        mkdir -p {COMPUTEDIR}/${{prefix}} && \
        parallel -j {params.threads} \
            --tmpdir {COMPUTEDIR}/${{prefix}} \
            --files \
            lavToPsl {{}} stdout \
            ::: {WORKDIR}/{input.lav}/* && \
        mv {COMPUTEDIR}/${{prefix}} {WORKDIR}/{output.psl}) 2> {log}
        """

# Rule: lastz
# Purpose: Performs pairwise genome alignments using LASTZ in parallel
# Input: Split genome files for target and query
# Output: Directory of LAV format alignments
rule lastz:
    input:
        target = REFGENOME+".ref.split",
        query = "{id}.fna.split"
    output:
        lastz = directory("{id}.fna.split.lastz")
    params:
        cluster="-cwd -V",
        threads = 16
    log:
        "logs/lastz/{id}.log"
    shell:"""
        (prefix=`date --rfc-3339=ns | md5sum | head -c 16` && \
        mkdir -p {COMPUTEDIR}/${{prefix}} && \
        parallel -j {params.threads} \
            --tmpdir {COMPUTEDIR}/${{prefix}} \
            --files \
            lastz {{1}} {{2}} \
            ::: {WORKDIR}/{input.target}/* \
            ::: {WORKDIR}/{input.query}/* && \
        mv {COMPUTEDIR}/${{prefix}} {WORKDIR}/{output.lastz}) 2> {log}
        """
## Genome Processing Rules ##
# Rule: splitFileREF
# Purpose: Splits reference genome into individual chromosomes and converts to NIB format
# Input: Masked reference genome file
# Output: Directory of NIB format chromosome files
rule splitFileREF:
    input:
        ref = REFGENOME+".ref.masked"
    output:
        split = directory(REFGENOME+".ref.split")
    log:
        "logs/splitfile/ref_split.log"
    shell:"""
        (mkdir -p {WORKDIR}/{output.split} && \
        faSplit byName {WORKDIR}/{input.ref} {WORKDIR}/{output.split}/ && \
        for i in {WORKDIR}/{output.split}/*.fa; do \
            faToNib $i `echo $i | sed -e s/.fa/.nib/`; \
        done && \
        rm {WORKDIR}/{output.split}/*.fa) 2> {log}
        """

# Rule: splitFile
# Purpose: Splits query genome into individual chromosomes and converts to NIB format
# Input: Masked query genome file
# Output: Directory of NIB format chromosome files
rule splitFile:
    input:
        genome = "{id}.fna.masked"
    output:
        split = directory("{id}.fna.split")
    log:
        "logs/splitfile/{id}_split.log"
    shell:"""
        (mkdir -p {WORKDIR}/{output.split} && \
        faSplit byName {WORKDIR}/{input.genome} {WORKDIR}/{output.split}/ && \
        for i in {WORKDIR}/{output.split}/*.fa; do \
            faToNib $i `echo $i | sed -e s/.fa/.nib/`; \
        done && \
        rm {WORKDIR}/{output.split}/*.fa) 2> {log}
        """

## Repeat Masking Rules ##
# Rule: repeatMaskerREF
# Purpose: Masks repetitive sequences in reference genome using RepeatMasker
# Input: Reference genome FASTA file
# Output: Masked reference genome
rule repeatMaskerREF:
    input:
        ref = REFGENOME+".ref"
    output:
        masked = REFGENOME+".ref.masked"
    threads: 16
    params:
        cluster="-cwd -V",
        species = "fungi",  # Specify taxonomic group for repeat library
        quiet = "-qq"  # Run in quiet mode
    log:
        "logs/masking/ref_masking.log"
    shell:"""
        (RepeatMasker {params.quiet} \
            -pa {threads} \
            -species {params.species} \
            {WORKDIR}/{input.ref}) 2> {log}
        """

# Rule: repeatMasker
# Purpose: Masks repetitive sequences in query genome using RepeatMasker
# Input: Query genome FASTA file
# Output: Masked query genome
rule repeatMasker:
    input:
        genome = "{id}.fna"
    output:
        masked = "{id}.fna.masked"
    threads: 16
    params:
        cluster="-cwd -V",
        species = "fungi",  # Specify taxonomic group for repeat library
        quiet = "-qq"  # Run in quiet mode
    log:
        "logs/masking/{id}_masking.log"
    shell:"""
        (RepeatMasker {params.quiet} \
            -pa {threads} \
            -species {params.species} \
            {WORKDIR}/{input.genome}) 2> {log}
        """
## Utility Rules ##
# Rule: genomeSizeREF
# Purpose: Calculates detailed size statistics for reference genome
# Input: Reference genome FASTA file
# Output: File containing chromosome sizes
rule genomeSizeREF:
    input:
        ref = REFGENOME+".ref"
    output:
        sizes = REFGENOME+".ref.sizes"
    log:
        "logs/commodity/ref_size.log"
    shell:"""
        (faSize {WORKDIR}/{input.ref} -detailed > {WORKDIR}/{output.sizes}) 2> {log}
        """

# Rule: genomeSize
# Purpose: Calculates detailed size statistics for query genome
# Input: Query genome FASTA file
# Output: File containing chromosome sizes
rule genomeSize:
    input:
        genome = "{id}.fna"
    output:
        sizes = "{id}.fna.sizes"
    log:
        "logs/commodity/{id}_size.log"
    shell:"""
        (faSize {WORKDIR}/{input.genome} -detailed > {WORKDIR}/{output.sizes}) 2> {log}
        """

## Cleanup Rule ##
# Rule: clean
# Purpose: Removes all intermediate and output files from the workflow
rule clean:
    params:
        patterns = [
            "*.sizes",    # Genome size files
            "*.masked",   # Masked genome files
            "*.split",    # Split genome directories
            "*.lastz",    # LASTZ alignment files
            "*.psl",      # PSL format alignments
            "*.chain",    # Chain format alignments
            "*.preChain", # Pre-processed chain files
            "*.net",      # Network format alignments
            "*.maf",      # MAF format alignments
            "*.axt",      # AXT format alignments
            "*.sh.*",     # Shell script logs
            "*.out",      # Output files
            "*.tbl",      # Table files
            "*.cat",      # Concatenated files
            "logs"        # Log directory
        ]
    shell: 
        "rm -rf {params.patterns}"

